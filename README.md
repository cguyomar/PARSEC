## Introduction

**PARSEC** is a bioinformatics pipeline designed to genotype large populations using low coverage (typically <3X) sequencing data.
Three imputation software are available as of today :
- [`Stitch`](https://github.com/rwdavies/STITCH)
- [`Glimpse1`](https://odelaneau.github.io/GLIMPSE/glimpse1/index.html)
- [`Beagle4`](https://faculty.washington.edu/browning/beagle/b4_0.html)

**The pipeline is still in development, please reach out if you need help for running it or encounter bugs**

![metro map](docs/images/PARSEC_metro_map.png)

1. Index bams ([`SAMtools`](https://sourceforge.net/projects/samtools/files/samtools/))
2. Prepare fixed size genomic chunks ([`bedtools`](https://github.com/arq5x/bedtools2/))
3. Optionnal : call variants from sparse data
   1. Merge bams on each window ([`SAMtools`](https://sourceforge.net/projects/samtools/files/samtools/))
   2. Call variants for each window ([`bcftools`](http://www.htslib.org/download/))
   3. Concatenate vcf files ([`bcftools`](http://www.htslib.org/download/))
   4. Sort vcf ([`bcftools`](http://www.htslib.org/download/))
   5. Filter variants  ([`bcftools`](http://www.htslib.org/download/))
6. Impute genotypes ([`stitch`](https://github.com/rwdavies/STITCH)
7. Index vcf ([`Tabix`](http://www.htslib.org/doc/tabix.html))
8. Concatenate vcf files  ([`bcftools`](http://www.htslib.org/download/))
9. Sort vcf  ([`bcftools`](http://www.htslib.org/download/))


## Usage

### Inputs

#### Aligned reads

PARSEC takes `bam` files as input. It is advised to perform duplicated marking and eventually BQSR recalibration on the bam files.
[Sarek](https://nf-co.re/sarek) can be used to automate read alignement (by not specifying any calling tool and eventually adding `--skip_tools baserecalibrator`)

#### Reference panel

Depending on the imputation method used, it may be necessary to supply a set of (preferentially phased) known variants (aka reference panel)
- `Glimpse` requires a reference panel supplied with `--ref_panel`
- `Beagle` can take a reference panel supplied with `--ref_panel` as a facultative input
- `Stitch` does not require a reference panel, but requires a set of SNP position, supplied as a vcf file (genotypes are not used). PARSEC can build it automatically using the `calling` subworkflow, but it is advised to validate it before running imputation. A good practice would be to run PARSEC a first time with `--skip_imputation`, hard filter the obtained variants, and run a second PARSEC run with `--sparse_variants` with the output of the first run


| Tool        | VCF Reference panel supplied with `--ref_panel` | VCF of SNPs supplied with `--sparse_variants`                  |
|-------------|-------------------------------------------------|----------------------------------------------------------------|
| **Glimpse** | ✅ Mandatory                                     | ❌ Not applicable                                               |
| **Beagle**  | ⚠️ Facultative                                   | ❌ Not applicable                                               |
| **Stitch**  | ❌ Not applicable                                | ✅ Recommended (hard-filtered output of a PARSEC `calling` run) |


> **Note**
> If you are new to Nextflow and nf-core, please refer to [this page](https://nf-co.re/docs/usage/installation) on how
> to set-up Nextflow. Make sure to [test your setup](https://nf-co.re/docs/usage/introduction#how-to-run-a-pipeline)
> with `-profile test` before running the workflow on actual data.

<!-- TODO nf-core: Describe the minimum required steps to execute the pipeline, e.g. how to prepare samplesheets.
     Explain what rows and columns represent. For instance (please edit as appropriate):

Imputation requires a list of variant positions supplied as a vcf (no sample information is needed).
This list can be generated by the pipeline using the calling subworflow or supplied by the user using the `--known_variants` option.

Here is a typical of the pipeline with the avaialble options :

```bash
nextflow run nf/sparse \
   -profile <docker/singularity/.../institute> \
   --bam "/path/to/data/*.bam" \
   --fasta genome.fa \
	--fai genome.fa.fai \
	--genome_bed genome.bed \
	--genome_sizes genome.sizes.txt  \
	--window_size 1000000 \
	--npop 10 \
	--ngen 100 \
	--buffer_size 100000 \
   --outdir <OUTDIR>
```

> **Warning:**
> Please provide pipeline parameters via the CLI or Nextflow `-params-file` option. Custom config files including those
> provided by the `-c` Nextflow option can be used to provide any configuration _**except for parameters**_;
> see [docs](https://nf-co.re/usage/configuration#custom-configuration-files).

## Credits

PARSEC was originally written in INRAE [GenPhyse](https://genphyse.toulouse.inra.fr/) by Cervin Guyomar.

## Contributions and Support

If you would like to contribute to this pipeline, please see the [contributing guidelines](.github/CONTRIBUTING.md).

## Citations

<!-- TODO nf-core: Add citation for pipeline after first release. Uncomment lines below and update Zenodo doi and badge at the top of this file. -->
<!-- If you use  nf/sparse for your analysis, please cite it using the following doi: [10.5281/zenodo.XXXXXX](https://doi.org/10.5281/zenodo.XXXXXX) -->

<!-- TODO nf-core: Add bibliography of tools and data used in your pipeline -->

An extensive list of references for the tools used by the pipeline can be found in the [`CITATIONS.md`](CITATIONS.md) file.

This pipeline uses code and infrastructure developed and maintained by the [nf-core](https://nf-co.re) community, reused here under the [MIT license](https://github.com/nf-core/tools/blob/master/LICENSE).

> **The nf-core framework for community-curated bioinformatics pipelines.**
>
> Philip Ewels, Alexander Peltzer, Sven Fillinger, Harshil Patel, Johannes Alneberg, Andreas Wilm, Maxime Ulysse Garcia, Paolo Di Tommaso & Sven Nahnsen.
>
> _Nat Biotechnol._ 2020 Feb 13. doi: [10.1038/s41587-020-0439-x](https://dx.doi.org/10.1038/s41587-020-0439-x).
